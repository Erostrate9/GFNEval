{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependency in Colab"
      ],
      "metadata": {
        "id": "7ptVYB2WbHFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git clone https://github.com/GFNOrg/torchgfn.git\n",
        "cd torchgfn\n",
        "pip install ."
      ],
      "metadata": {
        "id": "Wi6Q7515ciib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo (Pseudocode)"
      ],
      "metadata": {
        "id": "ewF0o8QWbJHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "from tqdm import tqdm\n",
        "\n",
        "from gfn.gflownet import TBGFlowNet\n",
        "from gfn.gym import HyperGrid\n",
        "from gfn.modules import DiscretePolicyEstimator\n",
        "from gfn.samplers import Sampler\n",
        "from gfn.utils.modules import MLP\n",
        "from gfn.states import DiscreteStates"
      ],
      "metadata": {
        "id": "BaPTfCCslZQi"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 - Find Available GPU resource\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 1 - Define the environment\n",
        "env = HyperGrid(ndim=4, height=8, R0=0.01)\n",
        "\n",
        "# 2 - Define the neural network modules\n",
        "module_PF = MLP(input_dim=env.preprocessor.output_dim, output_dim=env.n_actions)\n",
        "module_PB = MLP(input_dim=env.preprocessor.output_dim, output_dim=env.n_actions - 1, trunk=module_PF.trunk)\n",
        "\n",
        "# 3 - Define the estimators\n",
        "pf_estimator = DiscretePolicyEstimator(module_PF, env.n_actions, is_backward=False, preprocessor=env.preprocessor)\n",
        "pb_estimator = DiscretePolicyEstimator(module_PB, env.n_actions, is_backward=True, preprocessor=env.preprocessor)\n",
        "\n",
        "# 4 - Define the GFlowNet\n",
        "gfn = TBGFlowNet(logZ=0., pf=pf_estimator, pb=pb_estimator)\n",
        "\n",
        "# 5 - Define the sampler and optimizer\n",
        "sampler = Sampler(estimator=pf_estimator)\n",
        "optimizer = torch.optim.Adam(gfn.pf_pb_parameters(), lr=1e-3)\n",
        "optimizer.add_param_group({\"params\": gfn.logz_parameters(), \"lr\": 1e-1})\n",
        "\n",
        "# 6 - Train the GFlowNet\n",
        "for i in (pbar := tqdm(range(1000))):\n",
        "    trajectories = sampler.sample_trajectories(env=env, n=16)\n",
        "    optimizer.zero_grad()\n",
        "    loss = gfn.loss(env, trajectories).to(device)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i % 25 == 0:\n",
        "        pbar.set_postfix({\"loss\": loss.item()})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUZCEfP2k6_N",
        "outputId": "b550fc78-b1bf-4785-e451-28b7adaadd51"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [01:11<00:00, 13.94it/s, loss=0.161]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# TODO\n",
        "def compute_log_probability(gfn, state, memo={}):\n",
        "    \"\"\"\n",
        "    Recursively computes the log of the sampling probability π_θ(s) for a given terminal state `state`\n",
        "    in a GFlowNet `gfn` using torchgfn library.\n",
        "\n",
        "    Args:\n",
        "        gfn (GFlowNet): The GFlowNet model instance.\n",
        "        state (States): The terminal state for which we want to compute log π_θ(s).\n",
        "        memo (dict): A dictionary for memoization to store previously computed log probabilities.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The log probability π_θ(s).\n",
        "    \"\"\"\n",
        "    # Check if the result is already computed and stored in memo\n",
        "    if state in memo:\n",
        "        return memo[state]\n",
        "\n",
        "    # Base case: if the state is the initial state, log π_θ(s_initial) = 0\n",
        "    if state.is_initial_state.all():\n",
        "        log_prob = torch.tensor(0.0, requires_grad=False)\n",
        "        memo[state] = log_prob\n",
        "        return log_prob\n",
        "\n",
        "    # Recursive case: compute log π_θ(s) from parent states\n",
        "    # TODO: how to get the parents states?\n",
        "    parent_states = get_parents(state)\n",
        "\n",
        "    # Collect log-probabilities for each parent transition\n",
        "    log_probs = []\n",
        "    for parent_state in parent_states:\n",
        "        # Forward transition probability in log form\n",
        "        log_forward_prob = torch.log(gfn.get_forward_transition_probability(state, parent_state))\n",
        "\n",
        "        # Recursively compute log π_θ(parent_state)\n",
        "        log_parent_prob = compute_log_probability(gfn, parent_state, memo)\n",
        "\n",
        "        # Compute the sum inside the exponent for this parent\n",
        "        log_probs.append(log_forward_prob + log_parent_prob)\n",
        "\n",
        "    # Sum of exponentiated log-probabilities (log-sum-exp trick for numerical stability)\n",
        "    log_prob = torch.logsumexp(torch.stack(log_probs), dim=0)\n",
        "\n",
        "    # Memoize and return\n",
        "    memo[state] = log_prob\n",
        "    return log_prob"
      ],
      "metadata": {
        "id": "SbSucqUOyNLi"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 - Generate a test set and compute probabilities\n",
        "n_test = 100  # Number of test trajectories\n",
        "test_trajectories = sampler.sample_trajectories(env=env, n=n_test)"
      ],
      "metadata": {
        "id": "ifU5HtMPmuKS"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to hold the probabilities and rewards\n",
        "log_probs = []\n",
        "log_rewards = []\n",
        "memo = {}\n",
        "# Calculate the log probability and log reward for each terminal state\n",
        "for traj in test_trajectories:\n",
        "    terminal_states = traj[-1].states\n",
        "    reward = env.reward(terminal_state)\n",
        "    log_reward = np.log(reward)\n",
        "    # TODO\n",
        "    log_prob = compute_log_probability(gfn, terminal_states, memo)\n",
        "    log_probs.append(log_prob)\n",
        "    log_rewards.append(log_reward)"
      ],
      "metadata": {
        "id": "KgI8NYD7lcqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9 - Compute Spearman's Rank Correlation\n",
        "spearman_corr, _ = spearmanr(log_probs, log_rewards)\n",
        "print(f\"Spearman's Rank Correlation (GFNEvalS): {spearman_corr}\")"
      ],
      "metadata": {
        "id": "_C2XlrnOmzKA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}