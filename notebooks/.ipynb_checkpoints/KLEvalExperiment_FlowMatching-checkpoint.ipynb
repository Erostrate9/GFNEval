{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0xPFMzvYBCV"
   },
   "source": [
    "Download the KLEval_DB_results.pkl from [Google Drive](https://drive.google.com/file/d/15svCTwjA86sqGOCTeJC6SV21ImLSpW_4/view?usp=share_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cXehRxJbHxb",
    "outputId": "451f4bf4-1d08-4098-ddf1-e90437a10a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://sdawzy:****@github.com/Erostrate9/GFNEval.git#subdirectory=torchgfn\n",
      "  Cloning https://sdawzy:****@github.com/Erostrate9/GFNEval.git to /tmp/pip-req-build-8qc0x_cs\n",
      "  Running command git clone --filter=blob:none --quiet 'https://sdawzy:****@github.com/Erostrate9/GFNEval.git' /tmp/pip-req-build-8qc0x_cs\n",
      "  Resolved https://sdawzy:****@github.com/Erostrate9/GFNEval.git to commit 9b6bb6f73015be3f6817c28db9fb495ad84eb02d\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: torchgfn\n",
      "  Building wheel for torchgfn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torchgfn: filename=torchgfn-1.1.1-py3-none-any.whl size=82819 sha256=0f5154dc9daaf72191b9a400de50b33bc2fb28062c98aa813fca48a70274e129\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-26qx8dim/wheels/97/74/20/5c5130c3639d55c9ed0b3f7f003fa1a07cb97f41d8198db048\n",
      "Successfully built torchgfn\n",
      "Installing collected packages: torchgfn\n",
      "Successfully installed torchgfn-1.1.1\n"
     ]
    }
   ],
   "source": [
    "#@title Install Dependencies\n",
    "!find . -name \"*.pyc\" -delete\n",
    "!find . -name \"__pycache__\" -delete\n",
    "# !pip install --no-deps git+https://github.com/GFNOrg/torchgfn.git\n",
    "# Replace with your GitHub username and personal access token\n",
    "username = \"sdawzy\"\n",
    "token = \"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\"\n",
    "\n",
    "# Replace with your private repository URL\n",
    "repo_url = \"https://github.com/Erostrate9/GFNEval.git\"\n",
    "\n",
    "!pip install --no-deps git+https://{username}:{token}@{repo_url.split('https://')[1]}#subdirectory=torchgfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cSWpNpmXbSx-"
   },
   "outputs": [],
   "source": [
    "#@title Import Necessary Packages\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float)\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from gfn.gflownet import GFlowNet, TBGFlowNet, SubTBGFlowNet, FMGFlowNet, DBGFlowNet\n",
    "from gfn.samplers import Sampler\n",
    "from gfn.env import Env\n",
    "from gfn.modules import DiscretePolicyEstimator, ScalarEstimator\n",
    "from gfn.utils.modules import MLP , Tabular # is a simple multi-layer perceptron (MLP)\n",
    "from gfn.containers import Trajectories\n",
    "from gfn.states import States\n",
    "\n",
    "from gfn.eval_kl import PhiFunction, calc_KL_using_model, compute_KL\n",
    "from gfn.gym.hypergrid2 import HyperGrid2, get_final_states\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Z_0YZjmDgjDe"
   },
   "outputs": [],
   "source": [
    "#@title Experiment Setup, Traing, and Testing\n",
    "def experiment_setup(env : Env,  algo: GFlowNet):\n",
    "    gfn = None\n",
    "    sampler = None\n",
    "    optimizer = None\n",
    "\n",
    "    if algo is TBGFlowNet:\n",
    "        # The environment has a preprocessor attribute, which is used to preprocess the state before feeding it to the policy estimator\n",
    "        module_PF = MLP(\n",
    "            input_dim=env.preprocessor.output_dim,\n",
    "            output_dim=env.n_actions\n",
    "        ).to(env.device)  # Neural network for the forward policy, with as many outputs as there are actions\n",
    "        module_PB = MLP(\n",
    "            input_dim=env.preprocessor.output_dim,\n",
    "            output_dim=env.n_actions - 1,\n",
    "            trunk=module_PF.trunk  # We share all the parameters of P_F and P_B, except for the last layer\n",
    "        ).to(env.device)\n",
    "\n",
    "        pf_estimator = DiscretePolicyEstimator(module_PF, env.n_actions, is_backward=False, preprocessor=env.preprocessor).to(env.device)\n",
    "        pb_estimator = DiscretePolicyEstimator(module_PB, env.n_actions, is_backward=True, preprocessor=env.preprocessor).to(env.device)\n",
    "\n",
    "        gfn = TBGFlowNet(logZ=0., pf=pf_estimator, pb=pb_estimator).to(env.device)\n",
    "\n",
    "        sampler = Sampler(estimator=pf_estimator)\n",
    "\n",
    "        optimizer = torch.optim.Adam(gfn.pf_pb_parameters(), lr=1e-3)\n",
    "        optimizer.add_param_group({\"params\": gfn.logz_parameters(), \"lr\": 1e-1})\n",
    "\n",
    "    if algo is SubTBGFlowNet:\n",
    "        # The environment has a preprocessor attribute, which is used to preprocess the state before feeding it to the policy estimator\n",
    "        module_PF = MLP(\n",
    "            input_dim=env.preprocessor.output_dim,\n",
    "            output_dim=env.n_actions\n",
    "        ).to(env.device)  # Neural network for the forward policy, with as many outputs as there are actions\n",
    "\n",
    "        module_PB = MLP(\n",
    "            input_dim=env.preprocessor.output_dim,\n",
    "            output_dim=env.n_actions - 1,\n",
    "            trunk=module_PF.trunk  # We share all the parameters of P_F and P_B, except for the last layer\n",
    "        ).to(env.device)\n",
    "        module_logF = MLP(\n",
    "            input_dim=env.preprocessor.output_dim,\n",
    "            output_dim=1,  # Important for ScalarEstimators!\n",
    "        ).to(env.device)\n",
    "\n",
    "        # 3 - We define the estimators.\n",
    "        pf_estimator = DiscretePolicyEstimator(module_PF, env.n_actions, is_backward=False, preprocessor=env.preprocessor).to(env.device)\n",
    "        pb_estimator = DiscretePolicyEstimator(module_PB, env.n_actions, is_backward=True, preprocessor=env.preprocessor).to(env.device)\n",
    "        logF_estimator = ScalarEstimator(module=module_logF, preprocessor=env.preprocessor).to(env.device)\n",
    "\n",
    "        # 4 - We define the GFlowNet.\n",
    "        gfn = SubTBGFlowNet(pf=pf_estimator, pb=pb_estimator, logF=logF_estimator, lamda=0.9).to(env.device)\n",
    "\n",
    "        # 5 - We define the sampler and the optimizer.\n",
    "        sampler = Sampler(estimator=pf_estimator)  # We use an on-policy sampler, based on the forward policy\n",
    "\n",
    "        # Different policy parameters can have their own LR.\n",
    "        # Log F gets dedicated learning rate (typically higher).\n",
    "        optimizer = torch.optim.Adam(gfn.pf_pb_parameters(), lr=1e-3)\n",
    "        optimizer.add_param_group({\"params\": gfn.logF_parameters(), \"lr\": 1e-2})\n",
    "\n",
    "    if algo is DBGFlowNet:\n",
    "        # The environment has a preprocessor attribute, which is used to preprocess the state before feeding it to the policy estimator\n",
    "        module_PF = MLP(\n",
    "            input_dim=env.preprocessor.output_dim,\n",
    "            output_dim=env.n_actions\n",
    "        ).to(env.device)  # Neural network for the forward policy, with as many outputs as there are actions\n",
    "\n",
    "        module_PB = MLP(\n",
    "            input_dim=env.preprocessor.output_dim,\n",
    "            output_dim=env.n_actions - 1,\n",
    "            trunk=module_PF.trunk  # We share all the parameters of P_F and P_B, except for the last layer\n",
    "        ).to(env.device)\n",
    "        module_logF = MLP(\n",
    "            input_dim=env.preprocessor.output_dim,\n",
    "            output_dim=1,  # Important for ScalarEstimators!\n",
    "        ).to(env.device)\n",
    "\n",
    "        # 3 - We define the estimators.\n",
    "        pf_estimator = DiscretePolicyEstimator(module_PF, env.n_actions, is_backward=False, preprocessor=env.preprocessor).to(env.device)\n",
    "        pb_estimator = DiscretePolicyEstimator(module_PB, env.n_actions, is_backward=True, preprocessor=env.preprocessor).to(env.device)\n",
    "        logF_estimator = ScalarEstimator(module=module_logF, preprocessor=env.preprocessor).to(env.device)\n",
    "\n",
    "        # 4 - We define the GFlowNet.\n",
    "        gfn = DBGFlowNet(pf=pf_estimator, pb=pb_estimator, logF=logF_estimator).to(env.device)\n",
    "\n",
    "        # 5 - We define the sampler and the optimizer.\n",
    "        sampler = Sampler(estimator=pf_estimator)  # We use an on-policy sampler, based on the forward policy\n",
    "\n",
    "        # Different policy parameters can have their own LR.\n",
    "        # Log F gets dedicated learning rate (typically higher).\n",
    "        optimizer = torch.optim.Adam(gfn.pf_pb_parameters(), lr=1e-3)\n",
    "        optimizer.add_param_group({\"params\": gfn.logF_parameters(), \"lr\": 1e-2})\n",
    "\n",
    "    # TODO: initialize parameterizations of FMGFlowNet and DBGFlowNet\n",
    "\n",
    "    #flow matching:\n",
    "    if algo is FMGFlowNet:\n",
    "      module_PF = MLP(\n",
    "            input_dim=env.preprocessor.output_dim,\n",
    "            output_dim=env.n_actions\n",
    "        ).to(env.device)  # Neural network for the forward policy, with as many outputs as there are actions\n",
    "\n",
    "      module_PB = MLP(\n",
    "            input_dim=env.preprocessor.output_dim,\n",
    "            output_dim=env.n_actions - 1,\n",
    "            trunk=module_PF.trunk  # We share all the parameters of P_F and P_B, except for the last layer\n",
    "        ).to(env.device)\n",
    "      # module_logF = MLP(\n",
    "      #     input_dim=env.preprocessor.output_dim,\n",
    "      #     output_dim=1  # Important for ScalarEstimators!\n",
    "      # ).to(env.device)\n",
    "      module_logF = module = MLP(\n",
    "                input_dim=env.preprocessor.output_dim,\n",
    "                output_dim=env.n_actions,\n",
    "                hidden_dim=128,\n",
    "                n_hidden_layers=1,\n",
    "            )\n",
    "\n",
    "      pf_estimator = DiscretePolicyEstimator(module_PF, env.n_actions, is_backward=False, preprocessor=env.preprocessor).to(env.device)\n",
    "      pb_estimator = DiscretePolicyEstimator(module_PB, env.n_actions, is_backward=True, preprocessor=env.preprocessor).to(env.device)\n",
    "      logF_estimator = DiscretePolicyEstimator(module=module_logF, preprocessor=env.preprocessor,n_actions=env.n_actions).to(env.device)\n",
    "\n",
    "\n",
    "      # 4 - We define the GFlowNet.\n",
    "      gfn = FMGFlowNet(logF=logF_estimator).to(env.device)\n",
    "\n",
    "\n",
    "      # 5 - We define the sampler and the optimizer.\n",
    "      sampler = Sampler(estimator=logF_estimator)  # We use an on-policy sampler, based on the forward policy\n",
    "\n",
    "      # Different policy parameters can have their own LR.\n",
    "      # Log F gets dedicated learning rate (typically higher).\n",
    "      optimizer = torch.optim.Adam(gfn.logF.parameters(), lr=1e-3)\n",
    "      # parameters={\"params\":dict(gfn.named_parameters())['logF.module.trunk.0.weight'],'lr':1e-2}\n",
    "      # optimizer.add_param_group(parameters)\n",
    "\n",
    "    return gfn, sampler, optimizer\n",
    "\n",
    "def training(gfn: GFlowNet, sampler: Sampler, optimizer, num_epochs: int = 1000) -> Sampler:\n",
    "  for i in (pbar := tqdm(range(num_epochs))):\n",
    "    trajectories= sampler.sample_trajectories(env=env, n=16)\n",
    "    optimizer.zero_grad()\n",
    "    loss = gfn.loss(env, trajectories)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 25 == 0:\n",
    "      print(\"   Loss: \",loss.item())\n",
    "  return sampler\n",
    "\n",
    "\n",
    "\n",
    "def testing(env: Env, gfn: GFlowNet, num_samples: int = 10000, num_epochs: int = 250, show_progress: bool = False) -> None:\n",
    "    # Sample from proxy distribution\n",
    "    # i.e. from the learned sampler\n",
    "    samples_proxy_distribution = gfn.sample_terminating_states(env=env, n=num_samples)\n",
    "    samples_proxy_tensor = samples_proxy_distribution.tensor.double().to(env.device)\n",
    "\n",
    "    # Sample from the true distribution\n",
    "    samples_true_distribution = env.sample_states_from_distribution(num_samples)\n",
    "    samples_true_tensor = samples_true_distribution.tensor.double().to(env.device)\n",
    "\n",
    "    kl, phi = compute_KL(samples_proxy_tensor, samples_true_tensor,\n",
    "                         num_epochs=num_epochs, show_progress=show_progress)\n",
    "    return kl, phi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mEmrHka3c2XJ"
   },
   "outputs": [],
   "source": [
    "#@title Hyper-parameters\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "ndims =     [2, 4, 8, 16]\n",
    "heights =   [8, 16, 32, 64, 128, 256]\n",
    "ncenters =  [2, 4, 8, 16, 32]\n",
    "algos =     [TBGFlowNet, SubTBGFlowNet, FMGFlowNet, DBGFlowNet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lG2Ns5QYsSI",
    "outputId": "0e497e9c-0e14-4414-964b-e8dbcb067dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Loaded saved results from Google Drive.\n"
     ]
    }
   ],
   "source": [
    "#@title Load Progress\n",
    "drive.mount('/content/drive')\n",
    "drive_path = \"/content/drive/My Drive/KLEval_FM_results.pkl\"\n",
    "\n",
    "\n",
    "# Load saved results\n",
    "try:\n",
    "    with open(drive_path, \"rb\") as f:\n",
    "        results = pickle.load(f)\n",
    "    print(\"Loaded saved results from Google Drive.\")\n",
    "except FileNotFoundError:\n",
    "    results = {}  # Start fresh if no file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "pa_RmzSymxjt",
    "outputId": "e0d26897-eaa2-4e86-97d9-f480dadbebdd"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(4, 256, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ad73c5ee00d4>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                              \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              device_str='cpu')\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sampler'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_trajectories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (4, 256, 4)"
     ]
    }
   ],
   "source": [
    "#@title Some test\n",
    "env = HyperGrid2(ndim=4, height=256, ncenters=4,\n",
    "                             seed=torch.randint(0, 10000, (1,)).item(),\n",
    "                             device_str='cpu')\n",
    "sampler = results[(4,256,4)]['sampler']\n",
    "sampler.sample_trajectories(env=env, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vd6RK7GO3vun"
   },
   "outputs": [],
   "source": [
    "#@title (Optional) Reset results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c7tu8ATejYe"
   },
   "source": [
    "Start experiments from here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0j0Zz99ecBO",
    "outputId": "95efc855-e3fa-4618-f817-d3a0066acf37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Skipping already processed: ndim=2, height=8, ncenter=2\n",
      "Skipping already processed: ndim=2, height=8, ncenter=4\n",
      "Skipping already processed: ndim=2, height=8, ncenter=8\n",
      "Skipping already processed: ndim=2, height=8, ncenter=16\n",
      "Skipping already processed: ndim=2, height=8, ncenter=32\n",
      "Skipping already processed: ndim=2, height=16, ncenter=2\n",
      "Skipping already processed: ndim=2, height=16, ncenter=4\n",
      "Skipping already processed: ndim=2, height=16, ncenter=8\n",
      "Skipping already processed: ndim=2, height=16, ncenter=16\n",
      "Skipping already processed: ndim=2, height=16, ncenter=32\n",
      "Skipping already processed: ndim=2, height=32, ncenter=2\n",
      "Skipping already processed: ndim=2, height=32, ncenter=4\n",
      "Skipping already processed: ndim=2, height=32, ncenter=8\n",
      "Skipping already processed: ndim=2, height=32, ncenter=16\n",
      "Skipping already processed: ndim=2, height=32, ncenter=32\n",
      "Skipping already processed: ndim=2, height=64, ncenter=2\n",
      "Skipping already processed: ndim=2, height=64, ncenter=4\n",
      "Skipping already processed: ndim=2, height=64, ncenter=8\n",
      "Skipping already processed: ndim=2, height=64, ncenter=16\n",
      "Skipping already processed: ndim=2, height=64, ncenter=32\n",
      "Skipping already processed: ndim=2, height=128, ncenter=2\n",
      "Skipping already processed: ndim=2, height=128, ncenter=4\n",
      "Skipping already processed: ndim=2, height=128, ncenter=8\n",
      "Skipping already processed: ndim=2, height=128, ncenter=16\n",
      "Skipping already processed: ndim=2, height=128, ncenter=32\n",
      "Skipping already processed: ndim=2, height=256, ncenter=2\n",
      "Skipping already processed: ndim=2, height=256, ncenter=4\n",
      "Skipping already processed: ndim=2, height=256, ncenter=8\n",
      "Skipping already processed: ndim=2, height=256, ncenter=16\n",
      "Skipping already processed: ndim=2, height=256, ncenter=32\n",
      "Skipping already processed: ndim=4, height=8, ncenter=2\n",
      "Skipping already processed: ndim=4, height=8, ncenter=4\n",
      "Skipping already processed: ndim=4, height=8, ncenter=8\n",
      "Skipping already processed: ndim=4, height=8, ncenter=16\n",
      "Skipping already processed: ndim=4, height=8, ncenter=32\n",
      "Skipping already processed: ndim=4, height=16, ncenter=2\n",
      "Skipping already processed: ndim=4, height=16, ncenter=4\n",
      "Skipping already processed: ndim=4, height=16, ncenter=8\n",
      "Skipping already processed: ndim=4, height=16, ncenter=16\n",
      "Skipping already processed: ndim=4, height=16, ncenter=32\n",
      "Skipping already processed: ndim=4, height=32, ncenter=2\n",
      "Skipping already processed: ndim=4, height=32, ncenter=4\n",
      "Skipping already processed: ndim=4, height=32, ncenter=8\n",
      "Skipping already processed: ndim=4, height=32, ncenter=16\n",
      "Skipping already processed: ndim=4, height=32, ncenter=32\n",
      "Skipping already processed: ndim=4, height=64, ncenter=2\n",
      "Skipping already processed: ndim=4, height=64, ncenter=4\n",
      "Skipping already processed: ndim=4, height=64, ncenter=8\n",
      "Skipping already processed: ndim=4, height=64, ncenter=16\n",
      "Skipping already processed: ndim=4, height=64, ncenter=32\n",
      "Skipping already processed: ndim=8, height=8, ncenter=2\n",
      "Skipping already processed: ndim=8, height=8, ncenter=4\n",
      "Skipping already processed: ndim=8, height=8, ncenter=8\n",
      "Skipping already processed: ndim=8, height=8, ncenter=16\n",
      "ndim=8, height=8, ncenter=32, algo=FMGFlowNet\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:43<00:00,  4.47it/s, loss=0.912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial results saved to /content/drive/My Drive/KLEval_FM_results.pkl\n",
      "KL=7.9524584619187095\n",
      "Results saved to /content/drive/My Drive/KLEval_FM_results.pkl\n"
     ]
    }
   ],
   "source": [
    "device_str = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device_str)\n",
    "\n",
    "def training_flow_matching( gflownet, sampler,optimizer,num_epochs:int=1000)-> Sampler:\n",
    "\n",
    "  for i in (pbar := tqdm(range(num_epochs))) :\n",
    "    # trajectories = gflownet.sample_trajectories(\n",
    "    #         env,\n",
    "    #         n=env.n_actions,\n",
    "    #         save_estimator_outputs=False,\n",
    "    #         save_logprobs=True,\n",
    "    #     )\n",
    "    trajectories = sampler.sample_trajectories(env=env, n=16)\n",
    "    training_samples = gflownet.to_training_samples(trajectories)\n",
    "    # training_samples = gflownet.to_training_samples(trajectories)\n",
    "    optimizer.zero_grad()\n",
    "    loss = gflownet.loss(env, training_samples)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 25 == 0:\n",
    "      pbar.set_postfix({\"loss\": loss.item()})\n",
    "  return sampler\n",
    "\n",
    "\n",
    "\n",
    "# Specify the algorithm\n",
    "algo = FMGFlowNet\n",
    "for ndim in ndims:\n",
    "  for height in heights:\n",
    "    if height ** ndim > 1e8:\n",
    "        continue\n",
    "    for ncenter in ncenters:\n",
    "      if (ndim, height, ncenter) in results and 'seed' in results[(ndim, height, ncenter)]:\n",
    "        print(f\"Skipping already processed: ndim={ndim}, height={height}, ncenter={ncenter}\")\n",
    "        continue\n",
    "\n",
    "      print(f\"ndim={ndim}, height={height}, ncenter={ncenter}, algo=FMGFlowNet\")\n",
    "      seed = torch.randint(0, 10000, (1,)).item()\n",
    "      env = HyperGrid2(ndim=ndim, height=height, ncenters=ncenter,\n",
    "                        seed=seed,\n",
    "                        device_str=device_str)\n",
    "      gfn, sampler, optimizer = experiment_setup(env, algo)\n",
    "\n",
    "      sampler = training_flow_matching(gfn,sampler, optimizer)\n",
    "      # Save partial results\n",
    "      results[(ndim, height, ncenter)] = {\n",
    "          'sampler': sampler,  # Save the sampler object\n",
    "          'gfn': gfn,\n",
    "          'optimizer': optimizer,\n",
    "          'seed': seed,\n",
    "          'device_str': device_str,\n",
    "          # 'env': env,\n",
    "          'ndim': ndim,\n",
    "          'height': height,\n",
    "          'ncenter': ncenter,\n",
    "      }\n",
    "      with open(drive_path, \"wb\") as f:\n",
    "          pickle.dump(results, f)\n",
    "      print(f\"Partial results saved to {drive_path}\")\n",
    "\n",
    "      # Calculate KL and phi\n",
    "      kl, phi = testing(env, gfn)\n",
    "      print(f\"KL={kl}\")\n",
    "\n",
    "      # Save results\n",
    "      results[(ndim, height, ncenter)].update({\n",
    "          'kl': kl,\n",
    "          'phi': phi,\n",
    "      })\n",
    "      with open(drive_path, \"wb\") as f:\n",
    "          pickle.dump(results, f)\n",
    "      print(f\"Results saved to {drive_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcseLhSGa3rl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
