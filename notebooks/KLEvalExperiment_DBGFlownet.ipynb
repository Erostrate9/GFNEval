{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6154,"status":"ok","timestamp":1732329183090,"user":{"displayName":"Xiaowen Wang","userId":"07117555727439898487"},"user_tz":300},"id":"-cXehRxJbHxb","outputId":"d7571961-9609-406e-fab8-81c4e7f70218"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://sdawzy:****@github.com/Erostrate9/GFNEval.git#subdirectory=torchgfn\n","  Cloning https://sdawzy:****@github.com/Erostrate9/GFNEval.git to /tmp/pip-req-build-8w0dy9eu\n","  Running command git clone --filter=blob:none --quiet 'https://sdawzy:****@github.com/Erostrate9/GFNEval.git' /tmp/pip-req-build-8w0dy9eu\n","  Resolved https://sdawzy:****@github.com/Erostrate9/GFNEval.git to commit 1d3199f3c3432f227216b13ebf695bb37e1fde3a\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["#@title Install Dependencies\n","!find . -name \"*.pyc\" -delete\n","!find . -name \"__pycache__\" -delete\n","# !pip install --no-deps git+https://github.com/GFNOrg/torchgfn.git\n","# Replace with your GitHub username and personal access token\n","username = \"sdawzy\"\n","token = \"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\"\n","\n","# Replace with your private repository URL\n","repo_url = \"https://github.com/Erostrate9/GFNEval.git\"\n","\n","!pip install --no-deps git+https://{username}:{token}@{repo_url.split('https://')[1]}#subdirectory=torchgfn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cSWpNpmXbSx-"},"outputs":[],"source":["#@title Import Necessary Packages\n","import torch\n","torch.set_default_dtype(torch.float)\n","from torch import Tensor\n","from torch import nn\n","from torch import optim\n","\n","from gfn.gflownet import GFlowNet, TBGFlowNet, SubTBGFlowNet, FMGFlowNet, DBGFlowNet\n","from gfn.samplers import Sampler\n","from gfn.env import Env\n","from gfn.modules import DiscretePolicyEstimator, ScalarEstimator\n","from gfn.utils.modules import MLP  # is a simple multi-layer perceptron (MLP)\n","from gfn.containers import Trajectories\n","from gfn.states import States\n","\n","from gfn.eval_kl import PhiFunction, calc_KL_using_model, compute_KL\n","from gfn.gym.hypergrid2 import HyperGrid2, get_final_states\n","\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","import pickle\n","import os\n","from google.colab import drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_0YZjmDgjDe"},"outputs":[],"source":["#@title Experiment Setup, Traing, and Testing\n","def experiment_setup(env : Env,  algo: GFlowNet):\n","    gfn = None\n","    sampler = None\n","    optimizer = None\n","\n","    if algo is TBGFlowNet:\n","        # The environment has a preprocessor attribute, which is used to preprocess the state before feeding it to the policy estimator\n","        module_PF = MLP(\n","            input_dim=env.preprocessor.output_dim,\n","            output_dim=env.n_actions\n","        ).to(env.device)  # Neural network for the forward policy, with as many outputs as there are actions\n","        module_PB = MLP(\n","            input_dim=env.preprocessor.output_dim,\n","            output_dim=env.n_actions - 1,\n","            trunk=module_PF.trunk  # We share all the parameters of P_F and P_B, except for the last layer\n","        ).to(env.device)\n","\n","        pf_estimator = DiscretePolicyEstimator(module_PF, env.n_actions, is_backward=False, preprocessor=env.preprocessor).to(env.device)\n","        pb_estimator = DiscretePolicyEstimator(module_PB, env.n_actions, is_backward=True, preprocessor=env.preprocessor).to(env.device)\n","\n","        gfn = TBGFlowNet(logZ=0., pf=pf_estimator, pb=pb_estimator).to(env.device)\n","\n","        sampler = Sampler(estimator=pf_estimator)\n","\n","        optimizer = torch.optim.Adam(gfn.pf_pb_parameters(), lr=1e-3)\n","        optimizer.add_param_group({\"params\": gfn.logz_parameters(), \"lr\": 1e-1})\n","\n","    if algo is SubTBGFlowNet:\n","        # The environment has a preprocessor attribute, which is used to preprocess the state before feeding it to the policy estimator\n","        module_PF = MLP(\n","            input_dim=env.preprocessor.output_dim,\n","            output_dim=env.n_actions\n","        ).to(env.device)  # Neural network for the forward policy, with as many outputs as there are actions\n","\n","        module_PB = MLP(\n","            input_dim=env.preprocessor.output_dim,\n","            output_dim=env.n_actions - 1,\n","            trunk=module_PF.trunk  # We share all the parameters of P_F and P_B, except for the last layer\n","        ).to(env.device)\n","        module_logF = MLP(\n","            input_dim=env.preprocessor.output_dim,\n","            output_dim=1,  # Important for ScalarEstimators!\n","        ).to(env.device)\n","\n","        # 3 - We define the estimators.\n","        pf_estimator = DiscretePolicyEstimator(module_PF, env.n_actions, is_backward=False, preprocessor=env.preprocessor).to(env.device)\n","        pb_estimator = DiscretePolicyEstimator(module_PB, env.n_actions, is_backward=True, preprocessor=env.preprocessor).to(env.device)\n","        logF_estimator = ScalarEstimator(module=module_logF, preprocessor=env.preprocessor).to(env.device)\n","\n","        # 4 - We define the GFlowNet.\n","        gfn = SubTBGFlowNet(pf=pf_estimator, pb=pb_estimator, logF=logF_estimator, lamda=0.9).to(env.device)\n","\n","        # 5 - We define the sampler and the optimizer.\n","        sampler = Sampler(estimator=pf_estimator)  # We use an on-policy sampler, based on the forward policy\n","\n","        # Different policy parameters can have their own LR.\n","        # Log F gets dedicated learning rate (typically higher).\n","        optimizer = torch.optim.Adam(gfn.pf_pb_parameters(), lr=1e-3)\n","        optimizer.add_param_group({\"params\": gfn.logF_parameters(), \"lr\": 1e-2})\n","\n","    if algo is DBGFlowNet:\n","        # The environment has a preprocessor attribute, which is used to preprocess the state before feeding it to the policy estimator\n","        module_PF = MLP(\n","            input_dim=env.preprocessor.output_dim,\n","            output_dim=env.n_actions\n","        ).to(env.device)  # Neural network for the forward policy, with as many outputs as there are actions\n","\n","        module_PB = MLP(\n","            input_dim=env.preprocessor.output_dim,\n","            output_dim=env.n_actions - 1,\n","            trunk=module_PF.trunk  # We share all the parameters of P_F and P_B, except for the last layer\n","        ).to(env.device)\n","        module_logF = MLP(\n","            input_dim=env.preprocessor.output_dim,\n","            output_dim=1,  # Important for ScalarEstimators!\n","        ).to(env.device)\n","\n","        # 3 - We define the estimators.\n","        pf_estimator = DiscretePolicyEstimator(module_PF, env.n_actions, is_backward=False, preprocessor=env.preprocessor).to(env.device)\n","        pb_estimator = DiscretePolicyEstimator(module_PB, env.n_actions, is_backward=True, preprocessor=env.preprocessor).to(env.device)\n","        logF_estimator = ScalarEstimator(module=module_logF, preprocessor=env.preprocessor).to(env.device)\n","\n","        # 4 - We define the GFlowNet.\n","        gfn = DBGFlowNet(pf=pf_estimator, pb=pb_estimator, logF=logF_estimator).to(env.device)\n","\n","        # 5 - We define the sampler and the optimizer.\n","        sampler = Sampler(estimator=pf_estimator)  # We use an on-policy sampler, based on the forward policy\n","\n","        # Different policy parameters can have their own LR.\n","        # Log F gets dedicated learning rate (typically higher).\n","        optimizer = torch.optim.Adam(gfn.pf_pb_parameters(), lr=1e-3)\n","        optimizer.add_param_group({\"params\": gfn.logF_parameters(), \"lr\": 1e-2})\n","\n","    # TODO: initialize parameterizations of FMGFlowNet and DBGFlowNet\n","\n","    return gfn, sampler, optimizer\n","\n","def training(gfn: GFlowNet, sample: Sampler, optimizer, num_epochs: int = 1000) -\u003e Sampler:\n","    for i in (pbar := tqdm(range(num_epochs))):\n","        trajectories = sampler.sample_trajectories(env=env, n=16)\n","        optimizer.zero_grad()\n","\n","        transitions = trajectories.to_transitions()  # DBGFlowNet\n","\n","        loss = gfn.loss(env, transitions)\n","        loss.backward()\n","        optimizer.step()\n","        if i % 25 == 0:\n","            pbar.set_postfix({\"loss\": loss.item()})\n","    return sampler\n","\n","\n","\n","def testing(env: Env, gfn: GFlowNet, num_samples: int = 10000, num_epochs: int = 250, show_progress: bool = False) -\u003e None:\n","    # Sample from proxy distribution\n","    # i.e. from the learned sampler\n","    samples_proxy_distribution = gfn.sample_terminating_states(env=env, n=num_samples)\n","    samples_proxy_tensor = samples_proxy_distribution.tensor.double().to(env.device)\n","\n","    # Sample from the true distribution\n","    samples_true_distribution = env.sample_states_from_distribution(num_samples)\n","    samples_true_tensor = samples_true_distribution.tensor.double().to(env.device)\n","\n","    kl, phi = compute_KL(samples_proxy_tensor, samples_true_tensor,\n","                         num_epochs=num_epochs, show_progress=show_progress)\n","    return kl, phi\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEmrHka3c2XJ"},"outputs":[],"source":["#@title Hyper-parameters\n","seed = 1234\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","ndims =     [2, 4, 8, 16]\n","heights =   [8, 16, 32, 64, 128, 256]\n","ncenters =  [2, 4, 8, 16, 32]\n","algos =     [TBGFlowNet, SubTBGFlowNet, FMGFlowNet, DBGFlowNet]"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2103,"status":"ok","timestamp":1732329446257,"user":{"displayName":"Xiaowen Wang","userId":"07117555727439898487"},"user_tz":300},"id":"-lG2Ns5QYsSI","outputId":"bec53312-a1eb-45cd-c3b6-289877011827"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Loaded saved results from Google Drive.\n"]}],"source":["#@title Load Progress\n","drive.mount('/content/drive')\n","drive_path = \"/content/drive/My Drive/KLEval_DB_results.pkl\"\n","\n","\n","# Load saved results\n","try:\n","    with open(drive_path, \"rb\") as f:\n","        results = pickle.load(f)\n","    print(\"Loaded saved results from Google Drive.\")\n","except FileNotFoundError:\n","    results = {}  # Start fresh if no file exists"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":190},"collapsed":true,"executionInfo":{"elapsed":161,"status":"error","timestamp":1732329219067,"user":{"displayName":"Xiaowen Wang","userId":"07117555727439898487"},"user_tz":300},"id":"pa_RmzSymxjt","outputId":"f6d3afc1-0b69-499c-f538-efcca2ac7437"},"outputs":[{"ename":"KeyError","evalue":"(4, 256, 4)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-19-ad73c5ee00d4\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 5\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                              \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              device_str='cpu')\n\u001b[0;32m----\u003e 5\u001b[0;31m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sampler'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_trajectories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: (4, 256, 4)"]}],"source":["#@title Some test\n","env = HyperGrid2(ndim=4, height=256, ncenters=4,\n","                             seed=torch.randint(0, 10000, (1,)).item(),\n","                             device_str='cpu')\n","sampler = results[(4,256,4)]['sampler']\n","sampler.sample_trajectories(env=env, n=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vd6RK7GO3vun"},"outputs":[],"source":["#@title (Optional) Reset results\n","results = {}"]},{"cell_type":"markdown","metadata":{"id":"0c7tu8ATejYe"},"source":["Start experiments from here:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"b0j0Zz99ecBO"},"outputs":[{"name":"stdout","output_type":"stream","text":["Skipping already processed: ndim=2, height=8, ncenter=2\n","Skipping already processed: ndim=2, height=8, ncenter=4\n","Skipping already processed: ndim=2, height=8, ncenter=8\n","Skipping already processed: ndim=2, height=8, ncenter=16\n","Skipping already processed: ndim=2, height=8, ncenter=32\n","Skipping already processed: ndim=2, height=16, ncenter=2\n","Skipping already processed: ndim=2, height=16, ncenter=4\n","Skipping already processed: ndim=2, height=16, ncenter=8\n","Skipping already processed: ndim=2, height=16, ncenter=16\n","Skipping already processed: ndim=2, height=16, ncenter=32\n","Skipping already processed: ndim=2, height=32, ncenter=2\n","Skipping already processed: ndim=2, height=32, ncenter=4\n","Skipping already processed: ndim=2, height=32, ncenter=8\n","Skipping already processed: ndim=2, height=32, ncenter=16\n","Skipping already processed: ndim=2, height=32, ncenter=32\n","Skipping already processed: ndim=2, height=64, ncenter=2\n","Skipping already processed: ndim=2, height=64, ncenter=4\n","Skipping already processed: ndim=2, height=64, ncenter=8\n","ndim=2, height=64, ncenter=16, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [08:23\u003c00:00,  1.99it/s, loss=0.00436]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.13278466229649477\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=64, ncenter=32, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [07:49\u003c00:00,  2.13it/s, loss=0.00207]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.131430391766175\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=128, ncenter=2, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [13:42\u003c00:00,  1.22it/s, loss=0.0609]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=82.8769575707704\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=128, ncenter=4, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [14:21\u003c00:00,  1.16it/s, loss=0.00327]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.6212673336156782\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=128, ncenter=8, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [16:06\u003c00:00,  1.03it/s, loss=0.00754]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.4848860193566773\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=128, ncenter=16, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [16:20\u003c00:00,  1.02it/s, loss=0.0111]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.12457882293154035\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=128, ncenter=32, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [11:38\u003c00:00,  1.43it/s, loss=0.0597]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=1.1772048671475397\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=256, ncenter=2, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [28:59\u003c00:00,  1.74s/it, loss=0.029]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=4430.8009815999285\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=256, ncenter=4, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [21:21\u003c00:00,  1.28s/it, loss=0.00697]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=1.6717021326291226\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=256, ncenter=8, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [22:46\u003c00:00,  1.37s/it, loss=0.00584]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=1.7464710119600362\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=256, ncenter=16, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [24:20\u003c00:00,  1.46s/it, loss=0.0371]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=1.1534530208533504\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=2, height=256, ncenter=32, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [23:28\u003c00:00,  1.41s/it, loss=0.008]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=1.6479835328174701\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=8, ncenter=2, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [01:52\u003c00:00,  8.87it/s, loss=0.00561]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.15867069203992523\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=8, ncenter=4, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [02:04\u003c00:00,  8.04it/s, loss=0.00241]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.2307259684071652\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=8, ncenter=8, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [02:02\u003c00:00,  8.16it/s, loss=0.0273]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.22735925267254276\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=8, ncenter=16, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [02:04\u003c00:00,  8.06it/s, loss=0.0237]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.18345410907317317\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=8, ncenter=32, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [02:01\u003c00:00,  8.25it/s, loss=0.00513]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.10492724592269187\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=16, ncenter=2, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [03:06\u003c00:00,  5.35it/s, loss=0.0481]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.6885378175906796\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=16, ncenter=4, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [04:12\u003c00:00,  3.97it/s, loss=0.0173]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.19982453845973586\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=16, ncenter=8, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [03:44\u003c00:00,  4.45it/s, loss=0.0261]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.3332894945069642\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=16, ncenter=16, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [04:09\u003c00:00,  4.00it/s, loss=0.0187]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.23357279605812087\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=16, ncenter=32, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [04:05\u003c00:00,  4.07it/s, loss=0.0128]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.1902560642035464\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=32, ncenter=2, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [07:27\u003c00:00,  2.23it/s, loss=0.0587]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=4.257052600745059\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=32, ncenter=4, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [08:42\u003c00:00,  1.91it/s, loss=0.189]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=7.722582017529181\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=32, ncenter=8, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [07:22\u003c00:00,  2.26it/s, loss=0.0628]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=1.1994915937610517\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=32, ncenter=16, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [07:34\u003c00:00,  2.20it/s, loss=0.034]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.948849095991628\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=32, ncenter=32, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [07:35\u003c00:00,  2.19it/s, loss=0.155]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.648342270031042\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=64, ncenter=2, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [15:10\u003c00:00,  1.10it/s, loss=0.0692]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=214.29915819980428\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=64, ncenter=4, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [17:17\u003c00:00,  1.04s/it, loss=1.05]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=13.48469909454701\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=64, ncenter=8, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [12:34\u003c00:00,  1.32it/s, loss=0.209]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=30.297141963367366\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=64, ncenter=16, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [12:00\u003c00:00,  1.39it/s, loss=0.0154]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=54.04823738146004\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=4, height=64, ncenter=32, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [15:33\u003c00:00,  1.07it/s, loss=0.0983]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.8583035604627823\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=8, height=8, ncenter=2, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [04:01\u003c00:00,  4.14it/s, loss=0.0198]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=1.0497406218427714\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=8, height=8, ncenter=4, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [03:58\u003c00:00,  4.19it/s, loss=0.0348]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.5707727764047545\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=8, height=8, ncenter=8, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [03:26\u003c00:00,  4.84it/s, loss=0.0244]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.8055735665091679\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=8, height=8, ncenter=16, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [03:27\u003c00:00,  4.82it/s, loss=0.0542]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.6313184517147369\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","ndim=8, height=8, ncenter=32, algo=DB\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [03:36\u003c00:00,  4.61it/s, loss=0.115]\n"]},{"name":"stdout","output_type":"stream","text":["Partial results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n","KL=0.7066460371683976\n","Results saved to /content/drive/My Drive/KLEval_DB_results.pkl\n"]}],"source":["device_str = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Specify the algorithm\n","algo = DBGFlowNet\n","for ndim in ndims:\n","    for height in heights:\n","        if height ** ndim \u003e 1e8:\n","            continue\n","        for ncenter in ncenters:\n","            if (ndim, height, ncenter) in results and 'seed' in results[(ndim, height, ncenter)]:\n","                print(f\"Skipping already processed: ndim={ndim}, height={height}, ncenter={ncenter}\")\n","                continue\n","\n","            print(f\"ndim={ndim}, height={height}, ncenter={ncenter}, algo=DB\")\n","            seed = torch.randint(0, 10000, (1,)).item()\n","            env = HyperGrid2(ndim=ndim, height=height, ncenters=ncenter,\n","                             seed=seed,\n","                             device_str=device_str)\n","            gfn, sampler, optimizer = experiment_setup(env, algo)\n","\n","            sampler = training(gfn, sampler, optimizer)\n","            # Save partial results\n","            results[(ndim, height, ncenter)] = {\n","                'sampler': sampler,  # Save the sampler object\n","                'gfn': gfn,\n","                'optimizer': optimizer,\n","                'seed': seed,\n","                'device_str': device_str,\n","                # 'env': env,\n","                'ndim': ndim,\n","                'height': height,\n","                'ncenter': ncenter,\n","            }\n","            with open(drive_path, \"wb\") as f:\n","                pickle.dump(results, f)\n","            print(f\"Partial results saved to {drive_path}\")\n","\n","            # Calculate KL and phi\n","            kl, phi = testing(env, gfn)\n","            print(f\"KL={kl}\")\n","\n","            # Save results\n","            results[(ndim, height, ncenter)].update({\n","                'kl': kl,\n","                'phi': phi,\n","            })\n","            with open(drive_path, \"wb\") as f:\n","                pickle.dump(results, f)\n","            print(f\"Results saved to {drive_path}\")\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"gfn","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.15"}},"nbformat":4,"nbformat_minor":0}